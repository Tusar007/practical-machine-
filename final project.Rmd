---
title: "R programming"
author: "yeasin parvez"
date: "6/25/2020"
output:
  html_document:
    df_print: paged
  word_document: default
---
#Data Loading and Processing
```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(corrplot)
library(gbm)
```
#Getting, Cleaning and Exploring the data
```{r}
train_in <- read.csv('./pml-training.csv', header=T)
valid_in <- read.csv('./pml-testing.csv', header=T)
dim(train_in)
```
```{r}
dim(valid_in)
```
#Cleaning the input data
```{r}
trainData<- train_in[, colSums(is.na(train_in)) == 0]
validData <- valid_in[, colSums(is.na(valid_in)) == 0]
dim(trainData)
```
```{r}
dim(validData)
```
#We now remove the first seven variables as they have little impact on the outcome classe
```{r}
trainData <- trainData[, -c(1:7)]
validData <- validData[, -c(1:7)]
dim(trainData)
```
```{r}
dim(validData)
```
#Preparing the datasets for prediction
```{r}
set.seed(1234) 
inTrain <- createDataPartition(trainData$classe, p = 0.7, list = FALSE)
trainData <- trainData[inTrain, ]
testData <- trainData[-inTrain, ]
dim(trainData)
dim(testData)
```
#Cleaning even further by removing the variables that are near-zero-variance
```{r}
NZV <- nearZeroVar(trainData)
trainData <- trainData[, -NZV]
testData  <- testData[, -NZV]
dim(trainData)
dim(testData)
#After this cleaning we are down now to 49 variables
```
```{r}
cor_mat <- cor(trainData[, -53])
corrplot(cor_mat, order = "FPC", method = "color", type = "upper", 
         tl.cex = 0.8, tl.col = rgb(0, 0, 0))
```
#we use the findCorrelation function to search for highly correlated attributes with a cut off equal to 0.75
```{r}
highlyCorrelated = findCorrelation(cor_mat, cutoff=0.75)
names(trainData)[highlyCorrelated]#We then obtain the names of highly correlated attributes
```
#Model building
```{r}
#Prediction with classification trees
set.seed(12345)
decisionTreeMod1<-rpart(classe ~ ., data=trainData, method="class")
fancyRpartPlot(decisionTreeMod1)
#We then validate the model “decisionTreeModel” on the testData to find out how well it performs by looking at the accuracy variable
```
```{r}
predictTreeMod1 <- predict(decisionTreeMod1, testData, type = "class")
#cmtree <- confusionMatrix(predictTreeMod1, testData$classe)
c#mtree
```
```{r}
#plot matrix results
#plot(cmtree$table, col = cmtree$byClass, 
    # main = paste("Decision Tree - Accuracy =", #round(cmtree$overall['Accuracy'], 4)))
```
#Prediction with Random Forest
```{r}
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
modRF1 <- train(classe ~ ., data=trainData, method="rf", trControl=controlRF)
modRF1$finalModel
```
#We then validate the model obtained model “modRF1” on the test data to find out how well it performs by looking at the Accuracy variable
```{r}
predictRF1 <- predict(modRF1, newdata=testData)
#cmrf <- confusionMatrix(predictRF1, testData$classe)
#cmrf
```
#The accuracy rate using the random forest is very high: Accuracy : 1 and therefore the out-of-sample-error is equal to 0***. But it might be due to overfitting.
```{r}
plot(modRF1)
```
```{r}
#plot(cmrf$table, col = cmrf$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 4)))
```
#Prediction with Generalized Boosted Regression Models
```{r}
set.seed(12345)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modGBM  <- train(classe ~ ., data=trainData, method = "gbm", trControl = controlGBM, verbose = FALSE)
modGBM$finalModel
```
```{r}
# print model summary
print(modGBM)
```
```{r}
#Validate the GBM model
predictGBM <- predict(modGBM, newdata=testData)
#cmGBM <- confusionMatrix(predictGBM, testData$classe)
#cmGBM
```
#Applying the best model to the validation data
```{r}
Results <- predict(modRF1, newdata=validData)
Results
```



